{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from seaborn import violinplot\n",
    "from seaborn import boxplot\n",
    "from seaborn import histplot\n",
    "from seaborn import countplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### O DataSet a ser analisado será o \"Performance de estudantes\", onde reúne alguns parâmetros de à classe social e notas em diferentes provas (matemática e português) de alunos reais de duas escolas brasileiras (Gabriel Pereira e Mousinho da Silveira), no ano de 2008.\n",
    "\n",
    "##### O objetivo desta análise é entender melhor quais fatores podem contribuir mais para um determinado aluno conseguir ter um desempenho e aprendizado melhor, assim como poder prever, com um modelo simples, as notas mais prováveis de um aluno ter quando preenchendo alguns parâmetros.\n",
    "\n",
    "##### Este DataSet foi retirado do website [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu), e pode ser acessado por este [LINK](https://archive.ics.uci.edu/dataset/320/student+performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumário\n",
    "\n",
    ">- 1.....................................................Importação dos DataSets.\n",
    ">\n",
    ">   - 1.1........................................Definição de Funções.\n",
    ">    \n",
    ">- 2.....................................................Dicionário de Colunas.\n",
    ">\n",
    ">- 3.....................................................Preparação dos Dados.\n",
    ">\n",
    ">- 4.....................................................Uma análise exploratória.\n",
    ">\n",
    ">   - 4.1........................................Algumas análises Univariadas.\n",
    ">\n",
    ">   - 4.2........................................Algumas análises Bivariadas.\n",
    ">\n",
    ">       - 4.2.1...........................Relações de Nota vs Algumas variáveis categóricas.\n",
    ">\n",
    ">       - 4.2.2...........................Correlações das Variáveis numéricas.\n",
    ">\n",
    ">       - 4.2.3...........................Comportamento das médias.\n",
    ">\n",
    ">- 5.....................................................Considerações finais.\n",
    ">\n",
    ">   - 5.1........................................Conclusões e hipóteses.\n",
    ">\n",
    ">   - 5.2........................................Propostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    ">- 7.....................................................Planejamento dos Modelos.\n",
    ">\n",
    ">   - 7.1........................................O que queremos prever de fato ?\n",
    ">\n",
    ">   - 7.2........................................O que será feito, e como ?\n",
    ">\n",
    ">   - 7.3........................................Expectativa e próximos passos.\n",
    ">\n",
    ">- 8.....................................................Relação da EDA com a escolha das variáveis.\n",
    ">\n",
    ">- 9.....................................................Implementação dos Modelos.\n",
    ">\n",
    ">   - 9.1........................................Regressão Linear.\n",
    ">\n",
    ">   - 9.2........................................Árvore de Decisão.\n",
    ">\n",
    ">   - 9.3........................................KNN (K-Vizinhos mais Próximos).\n",
    ">\n",
    ">   - 9.4........................................Gradient Boosting.\n",
    ">\n",
    ">   - 9.5........................................Light GBM.\n",
    ">\n",
    ">- 10.....................................................Resultados e Métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumário de Imagens\n",
    "\n",
    "> Gráfico 1...............................................Barras - Quantidade de cada gênero.\n",
    ">\n",
    "> Gráfico 2...............................................Histograma - Frequência de cada nota por trimestre.\n",
    ">\n",
    "> Gráfico 3...............................................Boxplot - Outliers de falta.\n",
    ">\n",
    "> Gráfico 4...............................................Violino - Frequência de Notas por Escola\n",
    ">\n",
    "> Gráfico 5...............................................Violino - Frequência de Notas por tipo de endereço.\n",
    ">\n",
    "> Gráfico 6...............................................Violino - Frequência de Notas por tempo de deslocamento.\n",
    ">\n",
    "> Gráfico 7...............................................Violino - Frequência de Notas por suporte educacional.\n",
    ">\n",
    "> Gráfico 8...............................................Violino - Frequência de Notas por relação familiar.\n",
    ">\n",
    "> Gráfico 9...............................................Violino - Frequência de Notas por tamanho da família.\n",
    ">\n",
    "> Gráfico 10...............................................Mapa de Calor - Correlação das variáveis numéricas de Matemática.\n",
    ">\n",
    "> Gráfico 11............................................Mapa de Calor - Correlação das variáveis numéricas de Português.\n",
    ">\n",
    "> Gráfico 12............................................Linha - Tempo de Estudo por Média de nota.\n",
    ">\n",
    "> Gráfico 13............................................Barras e Linha - Quantidade de Cada educação de Pai/Mãe e Média de nota por Educação dos pais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Imagem 14...............................................Mapa de Calor - Correlação das notas de Matemática com escola, internet e ingresso em ensino superior.\n",
    ">\n",
    "> Imagem 15...............................................Mapa de Calor - Correlação das notas de Português com escola, internet e ingresso em ensino superior.\n",
    ">\n",
    "> Imagem 16...............................................Tabela - Resultados e métricas dos Modelos treinados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importação dos DataSets\n",
    "\n",
    "##### Após fazer a importação dos datasets, podemos ver qual a cara dos dados, como estão escritas variáveis categóricas, se há caracteres especiais, assim como utilizar funções que nos dê uma idéia de dados faltantes.\n",
    "\n",
    "##### No caso, podemos contar que estes datasets tem 1000 registros no total, e nenhum dos dados está nulo ou faltante, facilitando assim os próximos passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat = pd.read_csv(\"data/student-mat.csv\", sep=';')\n",
    "df_por = pd.read_csv(\"data/student-por.csv\", sep=';')\n",
    "dfs = [df_mat, df_por]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_por.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_mat Info\\n\")\n",
    "print(df_mat.info())\n",
    "print(\"\\n\\ndf_por Info\\n\")\n",
    "print(df_por.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_mat Quantidade Nulos\\n\")\n",
    "print(df_mat.isnull().sum())\n",
    "print(\"\\n\\ndf_por Quantidade Nulos\\n\")\n",
    "print(df_por.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Definição de Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showViolinPlot(var):\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "    sns.violinplot(x=var, y='G1', data=df_mat, ax=axes[0][0])\n",
    "    sns.violinplot(x=var, y='G2', data=df_mat, ax=axes[0][1])\n",
    "    sns.violinplot(x=var, y='G3', data=df_mat, ax=axes[0][2])\n",
    "\n",
    "    sns.violinplot(x=var, y='G1', data=df_por, ax=axes[1][0])\n",
    "    sns.violinplot(x=var, y='G2', data=df_por, ax=axes[1][1])\n",
    "    sns.violinplot(x=var, y='G3', data=df_por, ax=axes[1][2])\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            label = axes[i][j].get_xticklabels()\n",
    "            ticks = axes[i][j].get_xticks()\n",
    "            axes[i][j].set_xticks(ticks)\n",
    "            axes[i][j].set_xlabel(\"\")\n",
    "            axes[i][j].set_xticklabels(label)\n",
    "\n",
    "    axes[0][0].set_ylabel(\"Nota  1º  Trimestre  -  Matematica\")\n",
    "    axes[0][1].set_ylabel(\"Nota  2º  Trimestre  -  Matematica\")\n",
    "    axes[0][2].set_ylabel(\"Nota  3º  Trimestre  -  Matematica\")\n",
    "    axes[1][0].set_ylabel(\"Nota  1º  Trimestre  -  Portugues\")\n",
    "    axes[1][1].set_ylabel(\"Nota  2º  Trimestre  -  Portugues\")\n",
    "    axes[1][2].set_ylabel(\"Nota  3º  Trimestre  -  Portugues\")\n",
    "    \n",
    "    plt.tight_layout(w_pad=4, h_pad=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHeatmap(df, subject, colorPallete):\n",
    "    plt.figure(figsize=(14,9))\n",
    "    num = df.select_dtypes(include=['float', 'int'])\n",
    "    corr = num.corr()\n",
    "    matrix = np.triu(corr)\n",
    "    sns.heatmap(corr, annot=True, cmap=colorPallete, mask=matrix)\n",
    "    plt.title(\"Mapa de Calor de Correlações - \" + subject, fontsize=15)\n",
    "    plt.xticks(rotation=35)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showGenderQty(df):\n",
    "\n",
    "    bar = df['sex'].value_counts().reset_index()\n",
    "    percentages = bar['count'] / bar['count'].sum() * 100\n",
    "\n",
    "    plt.grid(False)\n",
    "\n",
    "    return bar, percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_decision_tree(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    tree = DecisionTreeRegressor(random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    Y_pred_tree = tree.predict(X_test)\n",
    "    mse_tree = mean_squared_error(y_test, Y_pred_tree)\n",
    "\n",
    "    return mse_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHeatmap(df, subject, colorPallete, index):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    num = df.select_dtypes(include=['float', 'int'])\n",
    "    corr = num.corr()\n",
    "    matrix = np.triu(corr)\n",
    "    sns.heatmap(corr, annot=True, cmap=colorPallete, mask=matrix)\n",
    "    plt.title(\"Mapa de Calor de Correlações - \" + subject, fontsize=15)\n",
    "    plt.xticks(rotation=35)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "    print(\"\\t\\tImagem \" + str(index) + \" - Mapa de Calor - Correlação das notas de \" + subject + \" com escola, internet e ingresso em ensino superior.\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_linear_regression(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_gradient_boosting_regression(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    gboost = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gboost.fit(X_train, y_train)\n",
    "\n",
    "    Y_pred_gboost = gboost.predict(X_test)\n",
    "\n",
    "    mse_gboost = mean_squared_error(y_test, Y_pred_gboost)\n",
    "    return mse_gboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_knn_regression(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    Y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "    mse_knn = mean_squared_error(y_test, Y_pred_knn)\n",
    "    return mse_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_light_gbm(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    lgb_model = lgbm.LGBMRegressor(n_estimators=100, random_state=42, verbosity=-1)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    Y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "    mse_lgb = mean_squared_error(y_test, Y_pred_lgb)\n",
    "    return mse_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = ['Matemática', 'Português']\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'materia': [],\n",
    "    'modelo': [],\n",
    "    'x': [],\n",
    "    'variavel_target': [],\n",
    "    'mse': [],\n",
    "    'r2': [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_linear_regression(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, r2, mae\n",
    "\n",
    "def pred_decision_tree(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    tree = DecisionTreeRegressor(random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    Y_pred_tree = tree.predict(X_test)\n",
    "    mse_tree = mean_squared_error(y_test, Y_pred_tree)\n",
    "    mae_tree = mean_absolute_error(y_test, Y_pred_tree)\n",
    "\n",
    "    return mse_tree, mae_tree\n",
    "\n",
    "def pred_gradient_boosting_regression(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    gboost = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gboost.fit(X_train, y_train)\n",
    "\n",
    "    Y_pred_gboost = gboost.predict(X_test)\n",
    "\n",
    "    mse_gboost = mean_squared_error(y_test, Y_pred_gboost)\n",
    "    mae_gboost = mean_absolute_error(y_test, Y_pred_gboost)\n",
    "    return mse_gboost, mae_gboost\n",
    "\n",
    "def pred_knn_regression(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    Y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "    mse_knn = mean_squared_error(y_test, Y_pred_knn)\n",
    "    mae_knn = mean_absolute_error(y_test, Y_pred_knn)\n",
    "    return mse_knn, mae_knn\n",
    "\n",
    "def pred_light_gbm(df, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=42)\n",
    "\n",
    "    lgb_model = lgbm.LGBMRegressor(n_estimators=100, random_state=42, verbosity=-1)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    Y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "    mse_lgb = mean_squared_error(y_test, Y_pred_lgb)\n",
    "    mae_lgb = mean_absolute_error(y_test, Y_pred_lgb)\n",
    "    return mse_lgb, mae_lgb\n",
    "\n",
    "df_names = ['Matemática', 'Português']\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'materia': [],\n",
    "    'modelo': [],\n",
    "    'x': [],\n",
    "    'variavel_target': [],\n",
    "    'mse': [],\n",
    "    'r2': [],\n",
    "    'mae': []\n",
    "})\n",
    "\n",
    "df_mat = pd.read_csv(\"data/student-mat.csv\", sep=';')\n",
    "df_por = pd.read_csv(\"data/student-por.csv\", sep=';')\n",
    "dfs = [df_mat, df_por]\n",
    "\n",
    "for i in (dfs):\n",
    "    i['Pstatus'] = i['Pstatus'].str.replace(\"A\", \"S\").str.replace(\"T\", \"J\")\n",
    "    i['sex'] = i['sex'].str.replace(\"M\", \"Masculino\").str.replace(\"F\", \"Feminino\")\n",
    "    i['address'] = i['address'].str.replace(\"R\", \"Rural\").str.replace(\"U\", \"Urbano\")\n",
    "    i['Mjob'] = i['Mjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "    i['Fjob'] = i['Fjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "    i['reason'] = i['reason'].str.replace(\"home\", \"Local\").str.replace(\"reputation\", \"Reputacao\").str.replace(\"course\", \"Curso\").str.replace(\"other\", \"Outro\")\n",
    "    i['guardian'] = i['guardian'].str.replace(\"mother\", \"Mae\").str.replace(\"father\", \"Pai\").str.replace(\"other\", \"Outro\")\n",
    "\n",
    "    i['schoolsup'] = i['schoolsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['famsup'] = i['famsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['paid'] = i['paid'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['activities'] = i['activities'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['nursery'] = i['nursery'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['higher'] = i['higher'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['internet'] = i['internet'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "    i['romantic'] = i['romantic'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "\n",
    "dfs[0] = pd.get_dummies(df_mat, columns=['school', 'higher', 'internet'])\n",
    "dfs[1] = pd.get_dummies(df_por, columns=['school', 'higher', 'internet'])\n",
    "\n",
    "for i in dfs:\n",
    "    i['school_GP'] = i['school_GP'].astype(int)\n",
    "    i['school_MS'] = i['school_MS'].astype(int)\n",
    "    i['higher_Nao'] = i['higher_Nao'].astype(int)\n",
    "    i['higher_Sim'] = i['higher_Sim'].astype(int)\n",
    "    i['internet_Nao'] = i['internet_Nao'].astype(int)\n",
    "    i['internet_Sim'] = i['internet_Sim'].astype(int)\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = ['G1', 'G2']\n",
    "    mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = ['G1', 'G2']\n",
    "    mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_gb, mae_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), mse_gb, '-', mae_gb]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_gb, mae_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), mse_gb, '-', mae_gb]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_gb, mae_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), mse_gb, '-', mae_gb]\n",
    "\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = ['G1', 'G2']\n",
    "    mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_lgbm, mae_lgbm = pred_light_gbm(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), mse_lgbm, '-', mae_lgbm]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_lgbm, mae_lgbm = pred_light_gbm(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), mse_lgbm, '-', mae_lgbm]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_lgbm, mae_lgbm = pred_light_gbm(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), mse_lgbm, '-', mae_lgbm]\n",
    "\n",
    "coefs['rmse'] = np.sqrt(coefs['mse'].astype(float))\n",
    "\n",
    "coefs['rmse'] = coefs['rmse'].apply(lambda x: round(x, 2))\n",
    "coefs['mse'] = coefs['mse'].apply(lambda x: round(x, 2))\n",
    "coefs['mae'] = coefs['mae'].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Dicionário de Colunas\n",
    "\n",
    "#### Para o melhor entendimento do que cada uma das categorias significa no contexto da análise, é necessário um dicionário de cada uma das colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **school**.......................................Escola (\"GP\" = Gabriel Pereira / \"MS\" = Mousinho da Silveira)\n",
    "\n",
    "2) **sex**..............................................Genero (\"F\" = Feminino / \"M\" = Masculino)\n",
    "3) **age**..............................................Idade do aluno\n",
    "4) **address**.....................................Tipo do endereço (\"U\" = Urbano / \"R\" = Rural)\n",
    "5) **famsize**.....................................Tamanho da Família (\"LE3\" = 3 Pessoas ou menos / \"GT3\" = Mais que 3 pessoas)\n",
    "6) **Pstatus**......................................Estatus dos pais (\"J\" = Morando juntos / \"S\" = Separados)\n",
    "7) **Medu**.........................................Educação da Mãe (0 = Nenhum / 1 = Fundamental / 2 = Quinto até Nono ano / 3 = Colégio / 4 = Ensino Superior)\n",
    "8) **Fedu**...........................................Educação do Pai (0 = Nenhum / 1 = Fundamental / 2 = Quinto até Nono ano / 3 = Colégio / 4 = Ensino Superior)\n",
    "9) **Mjob**..........................................Ocupação da Mãe (Professor / Saúde / Func. Público / Lar / Outro)\n",
    "10) **Fjob**............................................Ocupação do Pai (Professor / Saúde / Func. Público / Lar / Outro)\n",
    "11) **reason**.......................................Razão para escolher a escola (\"Local\" = Perto de casa / Reputação / \"Curso\" = Preferencia de curso / Outro)\n",
    "12) **guardian**..................................Guarda do estudante\n",
    "13) **traveltime**...............................Tempo de casa até a escola (1 = Menos que 15 min / 2 = 15 a 30 min / 3 = 30 min a 1 hora / 4 = Maior que 1 hora)\n",
    "14) **studytime**................................Tempo semanal de estudo (1 = Menos que 2 horas / 2 = 2 a 5 horas / 3 = 5 a 10 horas / 4 = Mais que 10 horas)\n",
    "15) **failures**......................................Número de vezes que o aluno repetiu de ano\n",
    "16) **schoolsup**................................Teve suporte educacional extra (Sim ou Não)\n",
    "17) **famsup**......................................Teve suporte educacional familiar (Sim ou Não)\n",
    "18) **paid**.............................................Teve aulas extras pagas dentro da disciplina do curso (Matemática ou Português) (Sim ou Não)\n",
    "19) **activities**...................................Teve atividades extracurriculares (Sim ou Não)\n",
    "20) **nursery**......................................Frequentou creche (Sim ou Não)\n",
    "21) **higher**.........................................Deseja cursar ensino superior (Sim ou Não)\n",
    "22) **internet**.....................................Tem acesso à internet em casa (Sim ou Não)\n",
    "23) **romantic**...................................Está em um relacionamento amoroso (Sim ou Não)\n",
    "24) **famrel**........................................Qualidade das relações familiares (De 1 = Muito ruim até 5 = Excelente)\n",
    "25) **freetime**....................................Tem tempo extra depois da escola (De 1 = Muito baixo até 5 = Muito alto)\n",
    "26) **goout**.........................................Sai com os amigos (De 1 = Muito baixo até 5 = Muito alto)\n",
    "27) **Dalc**.............................................Consumo de álcool durante a semana (De 1 = Muito baixo até 5 = Muito alto)\n",
    "28) **Walc**............................................Consumo de álcool no final de semana (De 1 = Muito baixo até 5 = Muito alto)\n",
    "29) **health**.........................................Estado de saúde atual (De 1 = Muito baixo até 5 = Muito alto)\n",
    "30) **absences**...................................Número de faltas na escola\n",
    "31) **G1**................................................Nota do primeiro trimestre (De 0 a 20)\n",
    "31) **G2**................................................Nota do segundo trimestre (De 0 a 20)\n",
    "32) **G3**................................................Nota final (terceiro trimestre) (De 0 a 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Preparação dos dados\n",
    "\n",
    "##### Não sendo necessário fazer nenmhum tratamento referente à dados faltantes, podemos tratar as variáveis categóricas\n",
    "\n",
    "##### Vamos realizar algumas preparações, como abreviações, traduções, mudanças que não causarão impacto à integridade dos dados, a fim de apenas facilitar o entendimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in (dfs):\n",
    "#     #i['school'] = i['school'].str.replace(\"GP\", str(1)).str.replace(\"MS\", str(0))\n",
    "#     i['Pstatus'] = i['Pstatus'].str.replace(\"A\", \"S\").str.replace(\"T\", \"J\")\n",
    "#     i['sex'] = i['sex'].str.replace(\"M\", \"Masculino\").str.replace(\"F\", \"Feminino\")\n",
    "#     i['address'] = i['address'].str.replace(\"R\", \"Rural\").str.replace(\"U\", \"Urbano\")\n",
    "#     i['Mjob'] = i['Mjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "#     i['Fjob'] = i['Fjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "#     i['reason'] = i['reason'].str.replace(\"home\", \"Local\").str.replace(\"reputation\", \"Reputacao\").str.replace(\"course\", \"Curso\").str.replace(\"other\", \"Outro\")\n",
    "#     i['guardian'] = i['guardian'].str.replace(\"mother\", \"Mae\").str.replace(\"father\", \"Pai\").str.replace(\"other\", \"Outro\")\n",
    "\n",
    "#     i['schoolsup'] = i['schoolsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['famsup'] = i['famsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['paid'] = i['paid'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['activities'] = i['activities'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['nursery'] = i['nursery'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['higher'] = i['higher'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['internet'] = i['internet'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['romantic'] = i['romantic'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "\n",
    "#     #i['school'] = i['school'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat2 = df_mat.copy()\n",
    "df_por2 = df_por.copy()\n",
    "\n",
    "df_mat2['school'] = df_mat2['school'].str.replace(\"GP\", str(1)).str.replace(\"MS\", str(0)).astype(int)\n",
    "df_mat2['schoolsup'] = df_mat2['schoolsup'].str.replace(\"Sim\", str(1)).str.replace(\"Nao\", str(0)).astype(int)\n",
    "df_mat2['address'] = df_mat2['address'].str.replace(\"Urbano\", str(1)).str.replace(\"Rural\", str(0)).astype(int)\n",
    "df_mat2['famsize'] = df_mat2['famsize'].str.replace(\"GT3\", str(1)).str.replace(\"LE3\", str(0)).astype(int)\n",
    "\n",
    "df_por2['school'] = df_por2['school'].str.replace(\"GP\", str(1)).str.replace(\"MS\", str(0)).astype(int)\n",
    "df_por2['schoolsup'] = df_por2['schoolsup'].str.replace(\"Sim\", str(1)).str.replace(\"Nao\", str(0)).astype(int)\n",
    "df_por2['address'] = df_por2['address'].str.replace(\"Urbano\", str(1)).str.replace(\"Rural\", str(0)).astype(int)\n",
    "df_por2['famsize'] = df_por2['famsize'].str.replace(\"GT3\", str(1)).str.replace(\"LE3\", str(0)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Uma análise exploratória\n",
    "\n",
    "### 4.1 - Algumas análises Univariadas\n",
    "\n",
    "##### Iniciaremos a análise vendo algumas variáveis separadamente, como estes dados mostram notas de provas de alunos, as três perguntas iniciais que queremos fazer são:\n",
    "\n",
    "1) Qual a proporção de homens e mulheres ?\n",
    "2) Quantas vezes cada nota foi obtida ?\n",
    "3) Há alguma variável da qual devemos nos preocupar com *outliers*, ou seja, valores muito fora da curva ?\n",
    "\n",
    "##### Podemos alcançar as respostas das 2 primeiras perguntas com gráficos de barra simples e histogramas. Já a terceira pergunta, baseado no dicionário das variáveis, como a maioria estão numa escala de 1 a 5, não haverão valores fugindo disto, apenas a variável *\"absences\"* (número de faltas) poderá nos mostrar algum valor discrepante, para ela, usaremos um gráfico de boxplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Os gráficos de barra abaixo mostram que para matemática, a quantidade de homens e mulheres são bem parecidas, porém em português, uma quantidade um pouco maior de dados de alunas foi coletado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "bar_mat = df_mat['sex'].value_counts().reset_index()\n",
    "percentages = bar_mat['count'] / bar_mat['count'].sum() * 100\n",
    "\n",
    "bar_mat.plot(kind='bar', x='sex', y='count', ax=axes[0], title='Quantidade por Genero - Matematica', legend=False)\n",
    "\n",
    "for i in range(0,1):\n",
    "    for j, percentage in enumerate(percentages):\n",
    "        axes[i].text(j, percentage, f\"{percentage:.2f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "axes[0].set_xlabel('Genero')\n",
    "axes[0].set_ylabel('Quantidade')\n",
    "axes[0].set_xticklabels([\"Feminino\", \"Masculino\"], rotation=0)\n",
    "\n",
    "\n",
    "\n",
    "bar_por = df_por['sex'].value_counts().reset_index()\n",
    "percentages = bar_por['count'] / bar_por['count'].sum() * 100\n",
    "\n",
    "bar_por.plot(kind='bar', x='sex', y='count', ax=axes[1], title='Quantidade por Genero - Portugues', legend=False)\n",
    "axes[1].set_xlabel('Genero')\n",
    "axes[1].set_ylabel('Quantidade')\n",
    "axes[1].set_xticklabels([\"Feminino\", \"Masculino\"], rotation=0)\n",
    "\n",
    "for i in range(1,2):\n",
    "    for j, percentage in enumerate(percentages):\n",
    "        axes[i].text(j, percentage, f\"{percentage:.2f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\t\\tGráfico 1 - Barras - Quantidade de cada gênero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Os 6 histogramas abaixo representam a frequência de cada nota, cada linha representa uma matéria, e cada coluna um trimestre do ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7))\n",
    "\n",
    "sns.histplot(df_mat['G1'], kde=True, ax=axes[0][0])\n",
    "sns.histplot(df_mat['G2'], kde=True, ax=axes[0][1])\n",
    "sns.histplot(df_mat['G3'], kde=True, ax=axes[0][2])\n",
    "\n",
    "sns.histplot(df_por['G1'], kde=True, ax=axes[1][0])\n",
    "sns.histplot(df_por['G2'], kde=True, ax=axes[1][1])\n",
    "sns.histplot(df_por['G3'], kde=True, ax=axes[1][2])\n",
    "\n",
    "for i in range(0,2):\n",
    "    for j in range(0,3):\n",
    "\n",
    "        if i == 0:\n",
    "            ylim = 80\n",
    "            sub = 'Matemática'\n",
    "        else:\n",
    "            ylim = 110\n",
    "            sub = 'Português'\n",
    "\n",
    "        if j == 0: axes[i][j].set_ylabel(\"Frequencia\")\n",
    "        else: axes[i][j].set_ylabel(\"\")\n",
    "\n",
    "        axes[i][j].set_xlabel(\"Nota \"+ str(j+1) +\"º Trimestre - \" + sub)\n",
    "\n",
    "        axes[i][j].set_ylim(0, ylim)\n",
    "        axes[i][j].set_xlim(0, 20)\n",
    "        axes[i][j].set_xticks(np.arange(0, 21, 2))\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        label = axes[i][j].get_xticklabels()\n",
    "        ticks = axes[i][j].get_xticks()\n",
    "        axes[i][j].set_xticks(ticks)\n",
    "        axes[i][j].set_xticklabels(label)\n",
    "\n",
    "plt.tight_layout(h_pad=3, w_pad=2)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\t\\tGráfico 2 - Histograma - Frequência de cada nota por trimestre.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Podemos concluir que, a quantidade de notas baixas aumentam com o passar do ano para ambas as matérias, porém este aumento é muito mais evidente em matemática. Da qual do 2º para o 3º trimestre, o número de alunos que tiraram nota 0 quase triplicaram.\n",
    "\n",
    "#### Este aumento significativo em matemática mas não tanto em português, pode ser causado pelos aumento da dificuldade da matéria, ou talvez a metodologia adotada pela escola. Outra análise poderá concluir algo correlacionando isso com alguma outra variável disponível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abaixo temos um gráfico boxplot da quantidade de faltas dos alunos, com o objetivo de analisar outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(df_mat.absences, orient=\"h\", ax=axes[0])\n",
    "sns.boxplot(df_por.absences, orient=\"h\", ax=axes[1])\n",
    "\n",
    "axes[0].set_xlabel(\"Faltas - Matematica\")\n",
    "axes[1].set_xlabel(\"Faltas - Portugues\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\t\\tGráfico 3 - Boxplot - Outliers de falta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos tirar duas principais conclusões com os gráficos acima:\n",
    "\n",
    "1) Alunos faltaram quase duas vezes mais às aulas de matemática do que português.\n",
    "2) Os alunos que tiveram uma falta muito acima da média, faltaram mais do que o dobro em matemática do que português, ou seja, emquanto temos 2 alunos que faltaram 30 ou 35 vezes me português, temos 5 alunos que faltaram mais de 35, 40, mais de 50 e até mais do que 70 vezes.\n",
    "\n",
    "#### Essas duas conclusões podem nos ajudar a entender o decaimento das notas de matemática, que embora tanto a nota quanto falta possam consequências de uma outra causa em comum, as faltas tem uma grande chance de ser um fator contribuinte para o decaimento das notas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Algumas análises Bivariadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 - Relações de Nota vs Algumas variáveis categóricas\n",
    "\n",
    "##### Tendo uma ideia inicial de como as variáveis se comportam e hipotetizando algumas possíveis causas pra esses comportamentos, vejamos como algumas dessas variáveis se comportam com relação à outras.\n",
    "\n",
    "##### Para isso, podemos pensar em algumas perguntas iniciais simples, que envolvam a nota e alguma variável categórica e não numérica:\n",
    "\n",
    "1) Há uma diferença entre notas dependendo de onde o aluno mora ?\n",
    "2) Há uma diferença entre notas dependendo de se o aluno teve algum suporte ou aula extra ?\n",
    "3) Há uma diferença entre notas dependendo do tamanho e relação familiar dos alunos ? \n",
    "4) Há uma diferença entre notas e a escola ?\n",
    "\n",
    "##### Vamos analisar algumas dessas questões utilizando gráficos de sino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showViolinPlot('school')\n",
    "print(\"\\t\\tGráfico 4 - Violino - Frequência de Notas por Escola.\")\n",
    "print(\"\\n\\t\\tGP - Gabriel Pereire\\n\\t\\tMS - Mousinho da Silveira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showViolinPlot('address')\n",
    "print(\"\\t\\tGráfico 5 - Violino - Frequência de Notas por tipo de endereço.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showViolinPlot('traveltime')\n",
    "print(\"\\t\\tGráfico 6 - Violino - Frequência de Notas por tempo de deslocamento.\")\n",
    "print(\"\\n\\t\\t1 - Menos de 15 minutos\\n\\t\\t2 - 15 a 30 Minutos\\n\\t\\t3 - 30 a 60 minutos\\n\\t\\t4 - Mais de 60 minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showViolinPlot('schoolsup')\n",
    "print(\"\\t\\tGráfico 7 - Violino - Frequência de Notas por suporte educacional.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showViolinPlot('famrel')\n",
    "print(\"\\t\\tGráfico 8 - Violino - Frequência de Notas por relação familiar.\")\n",
    "print(\"\\n\\t\\t1 - Muito ruim\\n\\t\\t2 - Ruim\\n\\t\\t3 - Normal\\n\\t\\t4 - Boa\\n\\t\\t5 - Excelente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showViolinPlot('famsize')\n",
    "print(\"\\t\\tGráfico 9 - Violino - Frequência de Notas por tamanho da família.\")\n",
    "print(\"\\n\\t\\tLE3 - Menor ou igual a 3 integrantes\\n\\t\\tGT3 - Mais que 3 integrantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Os gráficos acima nos permitem tirar algumas conclusões:\n",
    "\n",
    "1) Confirmação de que as notas, em todos os casos, diminuem ao longo do ano, principalmente em matemática.\n",
    "2) As notas de matemática nas escolas estão relativamente equilibradas, porém em português, há uma grande maioria de notas acima da média na escola Gabriel Pereira, e quase uma inexistência de notas 0, em contrapartida com a escola Mousinho da Silveira *(Gráfico 4)*.\n",
    "3) Alunos que moram em zona urbana tendem a ter uma concentração maior de notas acima da média e uma concentração menor de notas baixas *(Gráfico 5)*.\n",
    "4) Alunos que levam mais tempo se deslocando de casa para a escola tendem a ter notas menores *(Gráfico 6)*.\n",
    "5) Alunos com suporte educacional extra tendem a concentrar suas notas entre 7.5 e 10, enquanto alunos sem suporte tem uma frequencia de notas mais distribuidas. Porém apenas no começo do ano, do meio para frente, há um aumento de notas baixas e 0 para os alunos sem suporte *(Gráfico 7)*.\n",
    "6) A relação familiar do aluno interfere muito pouco para as suas notas, alunos com uma boa relação familiar até demonstram ter uma frequência de notas baixas um pouco maior do que alunos com uma má relação familiar *(Gráfico 8)*.\n",
    "7) Alunos com família maior de 3 pessoas tem uma maior concentração te notas baixas do que alunos com família menor *(Gráfico 9)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 - Correlações das Variáveis numéricas\n",
    "\n",
    "##### Vimos algumas relações das notas com variáveis categóricas, como as notas se relacionam com variáveis numéricas ? Posto isso, há perguntas que são importantes fazermos, por exemplo:\n",
    "\n",
    "1) Qual a correlação da nota com a educação dos pais ?\n",
    "2) Qual a correlação da nota com o numero de faltas ou repetições de ano ?\n",
    "3) Há uma correlação forte entre outras variáveis sem ser nota ? Essa correlação pode explicar alguma das hipóteses estipuladas até agora ?\n",
    "\n",
    "##### Fazemos isso calculando a correlação entre uma variável e outra, e gerando um número, variando de -1 a 1.\n",
    "\n",
    "##### Estes números são então colocados em uma matriz, e cada número é pintado de uma cor diferente, onde é possível saber qual variável se relaciona com qual, e se a correlação é forte ou fraca.\n",
    "\n",
    "##### ***OBS: O número da correlação, quanto mais próximo de 1, significa uma correlação positiva forte, ou seja são diretamente proporcionais, conforme uma variável sobe, a outra também sobe. Quanto mais próximo de -1, significa uma correlação negativa forte, ou seja inversamente proporcionais, conforme uma variável sobe, a outra desce. E quanto mais próximo de 0, significa que há muito pouca ou nenhuma correlação entre as variáveis.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHeatmap(df_mat2, 'Matemática', 'coolwarm', 10)\n",
    "print(\"\\t\\tGráfico 10 - Mapa de Calor - Correlação das variáveis numéricas de Matemática.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHeatmap(df_por2, 'Português', 'turbo', 11)\n",
    "print(\"\\t\\tGráfico 11 - Mapa de Calor - Correlação das variáveis numéricas de Português.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Com os mapas de calor acima, vemos alguns pontos interessantes:\n",
    "\n",
    "1) Há uma correlação positiva entre a educação dos pais e as notas (entre 0.15 e 0.26).\n",
    "2) Confirmamos que há uma correlação positiva entre a escola e a nota de português, porém não com à nota de matemática.\n",
    "3) Há uma correlação negativa entre a educação dos pais e o tempo que um aluno leva para chegar à escola (entre -0.27 a -0.16).\n",
    "4) Há uma correlação positiva forte entre as notas, alunos que tiraram notas boas em um trimestre dificilmente tiram notas ruins em outro (entre 0.8 e 0.92).\n",
    "5) *Confirmamos que quase não há correlação entre notas e relação familiar dos alunos, já que a relação familiar também não está correlacionado com quanto tempo o aluno estuda*.\n",
    "\n",
    "\n",
    "##### Sobre consumo de álcool\n",
    "\n",
    "*Há uma correlação negativa entre consumo de alcool e as notas, porém quase não há correlação entre nota e quantas vezes o aluno sai com os amigos para as notas em Português. Esta relação se inverte para as notas de Matemática, da qual quase não há correlação entre consumo de alcool e notas, porém há correlação negativa entre nota e quantas vezes o aluno sai*.\n",
    "\n",
    "##### Sobre tempo de estudo\n",
    "\n",
    "*Há uma correlação entre quanto tempo o aluno passa estudando e sua nota, ou seja, quanto mais tempo um aluno passa estudando, maior é a nota. Porém, essa correlação é quase o dobro em Português do que em Matemática. Podendo explicar o maior aumento de notas baixas durante o ano, significando que esta matéria fique bastante difícil com relação ao tempo, de maneira que nem um aluno que passa muito tempo estudando consiga um bom desempenho.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 - Comportamento das médias\n",
    "\n",
    "##### Com as observações vistas anteriormente, vamos colocar em alguns gráficos e tabelas, o comportamento da média das notas em relação à quanto tempo o aluno estuda e à educação dos pais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "study_time_mat = df_mat.groupby(['studytime'])[['G1', 'G2', 'G3']].mean().rename(index={1: '< 2 horas', 2: '2 a 5 horas', 3: '5 a 10 horas', 4: '> 10 horas'})\n",
    "study_time_por = df_por.groupby(['studytime'])[['G1', 'G2', 'G3']].mean().rename(index={1: '< 2 horas', 2: '2 a 5 horas', 3: '5 a 10 horas', 4: '> 10 horas'})\n",
    "\n",
    "groups = [study_time_mat, study_time_por]\n",
    "\n",
    "for i in range(0,2):\n",
    "    \n",
    "    if i%2 == 0: title = 'Matemática'\n",
    "    else: title = 'Português'\n",
    "    \n",
    "    groups[i][['G1', 'G2', 'G3']].plot(kind='line', ax=axes[i], title=title)\n",
    "    axes[i].set_xlabel('Tempo de estudo')\n",
    "    axes[i].set_ylabel('Média das Notas')\n",
    "    axes[i].grid(False)\n",
    "\n",
    "for j in range(0,2):\n",
    "\n",
    "    label = axes[j].get_xticklabels()\n",
    "    ticks = axes[j].get_xticks()\n",
    "    axes[j].set_xticks(ticks)\n",
    "    axes[j].set_xticklabels(label)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\t\\tGráfico 12 - Linha - Tempo de Estudo por Média de nota.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### O gráfico acima nos mostra que há um aumento na nota dos alunos que gastam mais tempo estudando, porém há comumente um decréscimo nas notas dos alunos que estudam mais de 10 horas.\n",
    "\n",
    "##### *Isso explica a diminuição na correlação, porém, com estes dados, não é possível pontuar com exatidão a causa para o fato dos alunos que mais estudam, diminuirem as notas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analisemos agora as notas com relação ao nivel educacional dos pais. Abaixo uma tabela com a média das notas de Matemática para cada nível de educação do Pai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "father_ed_prep_mat = df_mat.groupby(['Fedu'])[['G1', 'G2', 'G3']].mean().rename(index={0: 'Sem escolaridade', 1: 'Ensino Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Ensino Superior'})\n",
    "father_ed_prep_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Esta tabela nos mostra que conforme o nível educacional dos pais sobe, a nota média dos alunos aumenta um pouco, porém, há um ponto interessante, vemos que a maior média é justamente obtida por alunos cujo os pais não tem nenhuma escolaridade, por que isso ocorre ?\n",
    "\n",
    "##### Como a média é um número exato, podemos supor que há apenas 2 ou 1 alunos nesta condição, logo, com uma amostra pequena, irregularidades podem ocorrer, vamos plotar isso em uns gráficos, porém não só de matemática e educação do pai, mas sim todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(12, 16))\n",
    "\n",
    "bar_father_mat = df_mat['Fedu'].value_counts().reset_index()\n",
    "bar_father_por = df_por['Fedu'].value_counts().reset_index()\n",
    "bar_mother_mat = df_mat['Medu'].value_counts().reset_index()\n",
    "bar_mother_por = df_por['Medu'].value_counts().reset_index()\n",
    "bar_father_mat['Fedu'] = bar_father_mat['Fedu'].replace({0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "bar_father_por['Fedu'] = bar_father_por['Fedu'].replace({0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "bar_mother_mat['Medu'] = bar_mother_mat['Medu'].replace({0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "bar_mother_por['Medu'] = bar_mother_por['Medu'].replace({0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "father_ed_prep_mat = df_mat.groupby(['Fedu'])[['G1', 'G2', 'G3']].mean().rename(index={0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "father_ed_prep_por = df_por.groupby(['Fedu'])[['G1', 'G2', 'G3']].mean().rename(index={0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "mother_ed_prep_mat = df_mat.groupby(['Medu'])[['G1', 'G2', 'G3']].mean().rename(index={0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "mother_ed_prep_por = df_por.groupby(['Medu'])[['G1', 'G2', 'G3']].mean().rename(index={0: 'Nenhum', 1: 'Fundamental', 2: 'Ginásio', 3: 'Colégio', 4: 'Superior'})\n",
    "\n",
    "bars = [bar_father_mat, bar_father_por, bar_mother_mat, bar_mother_por]\n",
    "groups = [father_ed_prep_mat, father_ed_prep_por, mother_ed_prep_mat, mother_ed_prep_por]\n",
    "\n",
    "for i in range(0,4):\n",
    "\n",
    "    if i in [0,1]:\n",
    "        parent = 'Fedu'\n",
    "        label = 'Educação do Pai'\n",
    "    else:\n",
    "        parent = 'Medu'\n",
    "        label = 'Educação da Mãe'\n",
    "    \n",
    "    if i%2 == 0: title = 'Matemática'\n",
    "    else: title = 'Português'\n",
    "    \n",
    "    bars[i].plot(kind='bar', x=parent, y='count', ax=axes[i][0], title=title, legend=False)\n",
    "    axes[i][0].set_xlabel(label)\n",
    "    axes[i][0].set_ylabel('Quantidade')\n",
    "    axes[i][0].grid(False)\n",
    "\n",
    "    for x, value in enumerate(bars[i]['count']):\n",
    "        axes[i][0].text(x, value, str(value), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "\n",
    "    groups[i][['G1', 'G2', 'G3']].plot(kind='line', ax=axes[i][1], title=title)\n",
    "    axes[i][1].set_xlabel(label)\n",
    "    axes[i][1].set_ylabel('Média')\n",
    "    axes[i][1].grid(False)\n",
    "\n",
    "for i in range(0,4):\n",
    "    for j in range(0,2):\n",
    "\n",
    "        if j == 1: angle = 30\n",
    "        else: angle = 30\n",
    "\n",
    "        label = axes[i][j].get_xticklabels()\n",
    "        ticks = axes[i][j].get_xticks()\n",
    "        axes[i][j].set_xticks(ticks)\n",
    "        axes[i][j].set_xticklabels(label, rotation=angle)\n",
    "\n",
    "plt.tight_layout(h_pad=4)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\t\\tGráfico 13 - Barras e Linha - Quantidade de Cada educação de Pai/Mãe e Média de nota por Educação dos pais.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Os gráficos acima corroboram a informação de que uma amostra pequena está elevando a média. Apenas entre 3 e 7 alunos tem pais sem nenhuma escolaridade. Estes pouco alunos coincidentemente tiraram uma nota mais alta, o que fizeram elevar a nota média deste grupo, explicando essa anormalidade.\n",
    "\n",
    "##### É similar aos casos onde apenas 1 salário de um diretor ou presidente de empresa eleva a média salarial da empresa para um patamar muito alto, não condizente com o salário da grande maioria dos funcionários.\n",
    "\n",
    "##### Tirando isso, há uma consistência nos dados, em que quanto maior o nível educacional de um pai ou mãe, em média um pouco maior será a nota dos filhos, as notas dos 3 trimestres crescem de maneira quase uniforme, não tendo nenhuma discrepância entre elas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Considerações finais.\n",
    "\n",
    "### 5.1 - Conclusões e hipóteses.\n",
    "\n",
    "##### Ao final de tudo, podemos concluir que as notas dos alunos decaem ao longo do ano, este decaimento é mais evidente em Matemática\n",
    "\n",
    "Isso explica a diminuição na correlação, porém, com estes dados, não é possível pontuar com exatidão a causa para o fato dos alunos que mais estudam, diminuirem as notas.\n",
    "\n",
    "Como o alcool influencia negativamente nas notas de português, mas não tanto em matemática, o alcool está correlacionado à quanto tempo livre e quantas vezes o aluno sai, e quando somamos ao fato de que, para português, quanto mais tempo um aluno estuda maior a sua nota, porém o tempo de estudo não impacta tanto na nota de matemática.\n",
    "\n",
    "Tudo isso nos leva a crer que, há um menor tempo de dedicação aos estudos em matemática, e também há uma crescente complexidade na matéria ao longo do ano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Propostas.\n",
    "\n",
    "##### A escola pode implementar a seguinte medida para combater estes problemas:\n",
    "\n",
    "1) Aumentar interesse do aluno\n",
    "2) Recompensar esforço\n",
    "\n",
    "##### Aumentar o interesse do aluno em estudar matemática ao diminuir o foco em decorar fórmulas onde isso ocorre, ao invés, trazer problemas do ambiente do aluno para a sala de aula, mostrando onde tais numeros, fórmulas e metodologias se aplicam ao cotidiano do contexto em que o aluno está inserido, fazendo-o perceber como a matemática se aplica ao seu próprio dia a dia.\n",
    "\n",
    "##### Recompensar o esforço do aluno, diminuindo um pouco a quantidade e complexidade do conteúdo, ao decorar menos fórmulas e entender mais, o aluno se sente mais recompensado, e consequentemente mais motivado à estudar mais, quando vê que seu entendimento foi convertido em uma nota maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIM ENTREGA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação dos DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mat = pd.read_csv(\"data/student-mat.csv\", sep=';')\n",
    "# df_por = pd.read_csv(\"data/student-por.csv\", sep=';')\n",
    "# dfs = [df_mat, df_por]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados (tradução e One Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in (dfs):\n",
    "#     i['Pstatus'] = i['Pstatus'].str.replace(\"A\", \"S\").str.replace(\"T\", \"J\")\n",
    "#     i['sex'] = i['sex'].str.replace(\"M\", \"Masculino\").str.replace(\"F\", \"Feminino\")\n",
    "#     i['address'] = i['address'].str.replace(\"R\", \"Rural\").str.replace(\"U\", \"Urbano\")\n",
    "#     i['Mjob'] = i['Mjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "#     i['Fjob'] = i['Fjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "#     i['reason'] = i['reason'].str.replace(\"home\", \"Local\").str.replace(\"reputation\", \"Reputacao\").str.replace(\"course\", \"Curso\").str.replace(\"other\", \"Outro\")\n",
    "#     i['guardian'] = i['guardian'].str.replace(\"mother\", \"Mae\").str.replace(\"father\", \"Pai\").str.replace(\"other\", \"Outro\")\n",
    "\n",
    "#     i['schoolsup'] = i['schoolsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['famsup'] = i['famsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['paid'] = i['paid'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['activities'] = i['activities'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['nursery'] = i['nursery'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['higher'] = i['higher'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['internet'] = i['internet'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['romantic'] = i['romantic'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0] = pd.get_dummies(df_mat, columns=['school', 'higher', 'internet'])\n",
    "dfs[1] = pd.get_dummies(df_por, columns=['school', 'higher', 'internet'])\n",
    "\n",
    "for i in dfs:\n",
    "    i['school_GP'] = i['school_GP'].astype(int)\n",
    "    i['school_MS'] = i['school_MS'].astype(int)\n",
    "    i['higher_Nao'] = i['higher_Nao'].astype(int)\n",
    "    i['higher_Sim'] = i['higher_Sim'].astype(int)\n",
    "    i['internet_Nao'] = i['internet_Nao'].astype(int)\n",
    "    i['internet_Sim'] = i['internet_Sim'].astype(int)\n",
    "\n",
    "df_mat = dfs[0].copy()\n",
    "df_por = dfs[1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Planejamento dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Com os dados analisados e algumas conclusões feitas, o próximo passo é utilizar modelos de Machine Learning com o objetivo de prever as notas dos alunos com base em algumas características.\n",
    "\n",
    "##### Por exemplo, vimos que tempo de estudo e escola estão correlacionadas com as notas, com base nisso, o quão bem podemos prever a nota que um aluno vai ter, se soubermos apenas o quanto tempo ele estuda e qual escola ele estuda ? Esta é o principal questionamento que vamos responder nesta etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - O que queremos prever de fato ?\n",
    "\n",
    "##### Queremos prever a variável G1 e G2 (nota do 1º e 2º Trimestre, respectivamente) com base em algumas variáveis, e também confirmar o quão bem podemos prever a variável G3 (nota final) com base nas outras 2 notas.\n",
    "\n",
    "#### Variáveis a serem usadas nos modelos:\n",
    "- *failures* - Quantas vezes o aluno repetiu de ano.\n",
    "- *studytime* - Quantas horas o aluno passa estudando.\n",
    "- *school* - Qual escola o aluno estuda.\n",
    "- *Fedu* / *Medu* - Nível de educação da mãe e do pai.\n",
    "- *higher* - Se o aluno deseja ingressar num Ensino Superior.\n",
    "- *internet* - Se o aluno tem acesso à internet.\n",
    "\n",
    "#### Variáveis que não serão usadas nos modelos:\n",
    "- *traveltime* - Tempo que o aluno gasta se deslocando até a escola.\n",
    "- *famrel* - O quão boa é a relação familiar do aluno.\n",
    "- *goout* - O quão frequente ele sai com os amigos.\n",
    "- *health* - Saúde do aluno.\n",
    "- *absences* - Quantas vezes o aluno faltou.\n",
    "- *schoolsup* - Se o aluno teve suporte escolar.\n",
    "- *address* - Tipo de endereço que o aluno mora.\n",
    "- *famsize* - Tamanho da família."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - O que será feito, e como ?\n",
    "\n",
    "##### Vamos utilizar Modelos Supervisionados para previsão, isto é, um modelo onde já temos a resposta (no caso as notas), dividiremos os dados em 2 blocos: Treino e Teste, um bloco será usado para treinar o algoritmo, e o outro bloco será usado para testarmos o quão precisa foram as previsões do modelo.\n",
    "\n",
    "#### Modelos a serem utilizados:\n",
    "- *Regressão Linear*\n",
    "- *Árvore de Decisão*\n",
    "- *K - Vizinhos mais Próximos*\n",
    "- *Gradient Boosting*\n",
    "- *Light GBM*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - Expectativa e próximos passos\n",
    "\n",
    "##### Fazendo tudo isso, esperamos que os modelos identifiquem fatores-chave e apresentem uma precisão razoável na previsão das notas finais. Iremos captar as métricas e medições de acurácia dos modelos, para podermos avaliar qual deles está performando melhor e sendo mais pertinente para a nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Relação da EDA com a escolha das variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Como foi visto na Análise Exploratória anteriormente, podemos fazer algumas seleções de quais features iremos incluir ou remover.\n",
    "\n",
    "##### No item 2.1 acima, elencamos as variáveis à serem usadas: *failures* / *studytime* / *school* / *Fedu* / *Medu*\n",
    "\n",
    "##### Vimos que essas variáveis tem uma correlação positiva com as notas, então serão incluídas nos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Através das matrizes abaixo, alguns pontos muito importantes devem ser apontados:\n",
    "\n",
    "- Alunos com o intuito de ingressar em um ensino superior geralmente tem uma nota um pouco maior.\n",
    "- Alunos da escola Gabriel Pereira geralmente tem uma nota maior do que os alunos da escola Mousinho da Silveira.\n",
    "- Coincidentemente, a escola Gabriel Pereira tem uma quantidade de alunos com acesso à internet maior do que a escola Mousinho da Silveira.\n",
    "\n",
    "### Por causa destas observações, as variáveis *higher* / *internet* também serão inclusas nos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat_corr = df_mat.drop(columns=['age', 'address', 'famsize', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'])\n",
    "df_por_corr = df_por.drop(columns=['age', 'address', 'famsize', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'])\n",
    "corr_arr = [df_mat_corr, df_por_corr]\n",
    "index = [1, 2]\n",
    "\n",
    "for c, n, i in zip(corr_arr, df_names, index):\n",
    "    showHeatmap(c, n, 'coolwarm', i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Implementação dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Os modelos a serem treinados são os que já foram mencionados no item 2.2\n",
    "\n",
    "##### Abaixo contem o código que os executa\n",
    "\n",
    "##### Importante observar que em cada execução, é gerada um resultado e métricas de cada um, que são adicionados em uma tabela.\n",
    "\n",
    "##### Essa tabela será o principal objeto de estudo na próxima etapa desta análise, onde iremos dar uma olhada mais afundo nessas métricas, o que elas significam, saber qual algoritmo conseguiu performar melhor e fazer as melhores previsões, assim como o oposto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 - Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_lr, r2_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), f'{mse_lr:.2f}', f'{r2_lr:.2f}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_lr, r2_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), f'{mse_lr:.2f}', f'{r2_lr:.2f}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = ['G1', 'G2']\n",
    "    mse_lr, r2_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), f'{mse_lr:.2f}', f'{r2_lr:.2f}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_lr, r2_lr = pred_linear_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), f'{mse_lr:.2f}', f'{r2_lr:.2f}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), f'{mse_tree:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), f'{mse_tree:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = ['G1', 'G2']\n",
    "    mse_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), f'{mse_tree:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_tree = pred_decision_tree(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), f'{mse_tree:.2f}', '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - KNN (K-Vizinhos mais Próximos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), f'{mse_knn:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), f'{mse_knn:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = ['G1', 'G2']\n",
    "    mse_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), f'{mse_knn:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_knn = pred_knn_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), f'{mse_knn:.2f}', '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), f'{mse_gb:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), f'{mse_gb:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), f'{mse_gb:.2f}', '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 - Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    mse_lgbm = pred_light_gbm(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), f'{mse_lgbm:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    mse_lgbm = pred_light_gbm(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), f'{mse_lgbm:.2f}', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    mse_lgbm = pred_light_gbm(i, X, y)\n",
    "    coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), f'{mse_lgbm:.2f}', '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Resultados e Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(coefs)\n",
    "print(\"\\t\\tImagem 3 - Tabela - Resultados e métricas dos Modelos treinados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fim entrega 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Métricas utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como visto anteriormente, dar uma olhada mais afundo nas métricas, o que elas significam, saber qual algoritmo conseguiu performar melhor e fazer as melhores previsões, assim como o oposto.\n",
    "\n",
    "#### As métricas que vamos utilizar são:\n",
    "\n",
    "- *MSE - Erro quadrático médio*\n",
    "- *RMSE - Raiz do erro quadrático médio*\n",
    "- *R² - Coeficiente de determinação*\n",
    "- *MAE - Erro médio absoluto*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 - MSE - Erro quadrático médio\n",
    "\n",
    "##### Avalia o tamanho dos erros que o algoritmo está cometendo e os eleva ao quadrado, a fim de tornar os erros grandes ainda maiores.\n",
    "\n",
    "##### Este modelo nos ajuda a ver se o modelo está cometendo muitos erros grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 - RMSE - Raiz do erro quadrático médio\n",
    "\n",
    "##### Avalia o tamanho dos erros que o algoritmo está cometendo mas não os eleva ao quadrado.\n",
    "\n",
    "##### Este modelo nos ajuda a ver se o modelo está cometendo erros como o MSE porém estes erros estarão na mesma unidade da medição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 - R² - Coeficiente de determinação (Regressão Linear)\n",
    "\n",
    "##### Avalia o quão bem a Regressão Linear consegue explicar alguma coisa baseado em outras. Varia de 0 a 1, correspondendo à 0% e 100%\n",
    "\n",
    "##### Um R² de 0 significa que o modelo de Regressão Linear não explica nada e essencialmente é como se estivesse adivinhando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 - MAE - Erro médio absoluto\n",
    "\n",
    "##### O quão longe, em média, as previsões do modelo estão dos valores reais, ignorando se o valor é negativo ou positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Tabela de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A tabela acima nos mostra o seguinte:\n",
    "\n",
    "##### Para todos os modelos utilizados, quando utilizamos as variáveis: *repetições* / *tempo de estudo* / *escola* / *educação mãe* / *educação pai* / *interesse em ensino superior* / *acesso à internet*, para prever as notas G1 e G2. Vemos que o algoritmo comete muitos erros, e erros grandes.\n",
    "\n",
    "##### O MSE varia entre 7 para Português e 15 (chegando até 19) para Matemática. Porém considerando que a variável alvo varia entre 0 e 20. Um erro de MSE de 7 é bastante considerável.\n",
    "\n",
    "##### A Regressão Linear consegue prever aproximadamente 15 a 20% das notas dos alunos baseada nessas informações, e o acerto da previsão da nota final baseado nas outras notas é de aproximadamente 80%\n",
    "\n",
    "##### Por outro lado, considerando valores absolutos do MAE, observamos que a média dos erros do modelo não está tão longe dos valores reais. Eem média os maiores erros foram entre 2 e 3,5. Considerando a escala da variável entre 0 e 20, esta métrica mostrou que os modelos, quando não erraram bastante, tiveram uma taxa de acerto relativamente boa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões Finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com tudo o que vimos nos dados dos estudantes, podemos tirar algumas conclusões:\n",
    "\n",
    "1) Quanto mais tempo o aluno passa estudando, maior é a nota. Essa correlação é quase o dobro em Português do que em Matemática.\n",
    "\n",
    "2) Isso explica o aumento de notas baixas durante o ano, significando que esta matéria fique bastante difícil com relação ao tempo, de maneira que nem um aluno que passa muito tempo estudando consiga um bom desempenho.\n",
    "\n",
    "3) Há um menor tempo de dedicação aos estudos em matemática, por causa da crescente complexidade na matéria ao longo do ano, isso pode fazer com que os alunos acabem se \"desmotivando\" para estudar.\n",
    "\n",
    "4) Alunos da escola Gabriel Pereira tem uma nota em português maior do que os alunos da escola Mousinho da Silveira.\n",
    "\n",
    "5) A estrutura familiar do aluno não se relaciona tanto com a quantidade de horas que o aluno estuda e suas notas.\n",
    "\n",
    "6) Alunos da zona urbana tem uma média de notas superior à alunos que moram em área rual. Assim como os que estudam mais longe de casa tem uma nota menor dos que estudam mais perto de casa.\n",
    "\n",
    "7) Alunos com suporte educacional extra tendem a concentrar suas notas entre 7.5 e 10, alunos sem suporte adquirem uma frequência maior de notas 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propostas\n",
    "\n",
    "##### Propomos, então, a implementação dos seguintes modelos de modo a mitigar os principais problemas apresentados acima:\n",
    "\n",
    "## 1 - Aumentar interesse do aluno.\n",
    "\n",
    "##### Aumentar o interesse do aluno em estudar matemática ao diminuir o foco em decorar fórmulas onde isso ocorre, ao invés, trazer problemas mais palpáveis do ambiente do aluno para a sala de aula, mostrando onde tais numeros, fórmulas e metodologias se aplicam ao cotidiano do contexto em que o aluno está inserido, fazendo-o perceber como a matemática se aplica ao seu próprio dia a dia.\n",
    "\n",
    "##### Exemplo: como alunos em um contexto rural tem notas menores, podemos ensinar matemática num contexto rural e de campo, mostrando como a matemática se aplica em diferentes áreas e ciclos de plantio, como a matemática foi usada na construção de casas na época dos grandes latifúndios, conceitos de matemática e física que se aplicam à GPS, ferramenta muito usada no controle de máquinas agrícolas.\n",
    "\n",
    "## 2 - Recompensar esforço.\n",
    "\n",
    "##### Ao diminuir um pouco a quantidade e complexidade do conteúdo, ao decorar menos fórmulas e entender mais, o aluno se sente mais recompensado, e consequentemente mais motivado à estudar mais, quando vê que seu entendimento foi convertido em uma nota maior.\n",
    "\n",
    "##### Exemplo: Compor parte da média final com várias lições de casa e trabalhos, pode estimular o aluno à se dedicar apenas um pouco mais todos os dias, aumentando o número de horas que passa estudando sem nem perceber que está estudando, e não apenas motivar o aluno à estudar somente em vésperas de provas.\n",
    "\n",
    "## 3 - Estudo da escola Gabriel Pereira.\n",
    "\n",
    "##### Realizar um estudo mais aprofundado e detalhado sobre as diferenças das didáticas e planos estudantis das duas escolas:\n",
    "\n",
    "- Como são as aulas dos professores ? E suas formações ?\n",
    "- O quão atualizado é o material didático ? Há diferença entre eles ?\n",
    "- Há diferenças nos valores da escola ?\n",
    "- Como estão estruturados os horários e intervalos ?\n",
    "- Há diferença entre aplicabilidade de provas ?\n",
    "\n",
    "##### Estes questionamentos devem ser feitos a fim de entender melhor a causa das notas da escola Gabriel Pereira serem melhores, e, partir destes pontos, traçar um plano para a analisar as possíveis implementações e mudanças a serem feitas na escola Mousinho da Silveira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fim entrega 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pred_linear_regression(df, X, y):\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "\n",
    "#     modelo = LinearRegression()\n",
    "#     modelo.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = modelo.predict(X_test)\n",
    "\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#     return mse, r2, mae\n",
    "\n",
    "# def pred_decision_tree(df, X, y):\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "\n",
    "#     tree = DecisionTreeRegressor(random_state = 42)\n",
    "#     tree.fit(X_train, y_train)\n",
    "#     Y_pred_tree = tree.predict(X_test)\n",
    "#     mse_tree = mean_squared_error(y_test, Y_pred_tree)\n",
    "#     mae_tree = mean_absolute_error(y_test, Y_pred_tree)\n",
    "\n",
    "#     return mse_tree, mae_tree\n",
    "\n",
    "# def pred_gradient_boosting_regression(df, X, y):\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "\n",
    "#     gboost = GradientBoostingRegressor(n_estimators = 100, random_state = 42)\n",
    "#     gboost.fit(X_train, y_train)\n",
    "\n",
    "#     Y_pred_gboost = gboost.predict(X_test)\n",
    "\n",
    "#     mse_gboost = mean_squared_error(y_test, Y_pred_gboost)\n",
    "#     mae_gboost = mean_absolute_error(y_test, Y_pred_gboost)\n",
    "#     return mse_gboost, mae_gboost\n",
    "\n",
    "# def pred_knn_regression(df, X, y):\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     knn = KNeighborsRegressor(n_neighbors = 5)\n",
    "#     knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "#     Y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "#     mse_knn = mean_squared_error(y_test, Y_pred_knn)\n",
    "#     mae_knn = mean_absolute_error(y_test, Y_pred_knn)\n",
    "#     return mse_knn, mae_knn\n",
    "\n",
    "# def pred_light_gbm(df, X, y):\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "\n",
    "#     lgb_model = lgbm.LGBMRegressor(n_estimators = 100, random_state = 42, verbosity = -1)\n",
    "#     lgb_model.fit(X_train, y_train)\n",
    "\n",
    "#     Y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "#     mse_lgb = mean_squared_error(y_test, Y_pred_lgb)\n",
    "#     mae_lgb = mean_absolute_error(y_test, Y_pred_lgb)\n",
    "#     return mse_lgb, mae_lgb\n",
    "\n",
    "# df_names = ['Matemática', 'Português']\n",
    "\n",
    "# coefs = pd.DataFrame({\n",
    "#     'materia': [],\n",
    "#     'modelo': [],\n",
    "#     'x': [],\n",
    "#     'variavel_target': [],\n",
    "#     'mse': [],\n",
    "#     'r2': [],\n",
    "#     'mae': []\n",
    "# })\n",
    "\n",
    "# df_mat = pd.read_csv(\"data/student-mat.csv\", sep = ';')\n",
    "# df_por = pd.read_csv(\"data/student-por.csv\", sep = ';')\n",
    "# dfs = [df_mat, df_por]\n",
    "\n",
    "# for i in (dfs):\n",
    "#     i['Pstatus'] = i['Pstatus'].str.replace(\"A\", \"S\").str.replace(\"T\", \"J\")\n",
    "#     i['sex'] = i['sex'].str.replace(\"M\", \"Masculino\").str.replace(\"F\", \"Feminino\")\n",
    "#     i['address'] = i['address'].str.replace(\"R\", \"Rural\").str.replace(\"U\", \"Urbano\")\n",
    "#     i['Mjob'] = i['Mjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "#     i['Fjob'] = i['Fjob'].str.replace(\"at_home\", \"Lar\").str.replace(\"health\", \"Saude\").str.replace(\"other\", \"Outro\").str.replace(\"services\", \"Func. Publico\").str.replace(\"teacher\", \"Professor\")\n",
    "#     i['reason'] = i['reason'].str.replace(\"home\", \"Local\").str.replace(\"reputation\", \"Reputacao\").str.replace(\"course\", \"Curso\").str.replace(\"other\", \"Outro\")\n",
    "#     i['guardian'] = i['guardian'].str.replace(\"mother\", \"Mae\").str.replace(\"father\", \"Pai\").str.replace(\"other\", \"Outro\")\n",
    "\n",
    "#     i['schoolsup'] = i['schoolsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['famsup'] = i['famsup'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['paid'] = i['paid'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['activities'] = i['activities'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['nursery'] = i['nursery'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['higher'] = i['higher'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['internet'] = i['internet'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "#     i['romantic'] = i['romantic'].str.replace(\"yes\", \"Sim\").str.replace(\"no\", \"Nao\")\n",
    "\n",
    "# dfs[0] = pd.get_dummies(df_mat, columns = ['school', 'higher', 'internet'])\n",
    "# dfs[1] = pd.get_dummies(df_por, columns = ['school', 'higher', 'internet'])\n",
    "\n",
    "# for i in dfs:\n",
    "#     i['school_GP'] = i['school_GP'].astype(int)\n",
    "#     i['school_MS'] = i['school_MS'].astype(int)\n",
    "#     i['higher_Nao'] = i['higher_Nao'].astype(int)\n",
    "#     i['higher_Sim'] = i['higher_Sim'].astype(int)\n",
    "#     i['internet_Nao'] = i['internet_Nao'].astype(int)\n",
    "#     i['internet_Sim'] = i['internet_Sim'].astype(int)\n",
    "\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G1'\n",
    "#     mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G2'\n",
    "#     mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = ['G1', 'G2']\n",
    "#     mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['G1', 'G2']\n",
    "#     y = 'G3'\n",
    "#     mse_lr, r2_lr, mae_lr = pred_linear_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Regressao Linear', str(X), str(y), mse_lr, f'{r2_lr:.2f}', mae_lr]\n",
    "\n",
    "\n",
    "\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G1'\n",
    "#     mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G2'\n",
    "#     mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = ['G1', 'G2']\n",
    "#     mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['G1', 'G2']\n",
    "#     y = 'G3'\n",
    "#     mse_tree, mae_tree = pred_decision_tree(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Arvore de  Decisao', str(X), str(y), mse_tree, '-', mae_tree]\n",
    "\n",
    "\n",
    "\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G1'\n",
    "#     mse_gb, mae_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), mse_gb, '-', mae_gb]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G2'\n",
    "#     mse_gb, mae_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), mse_gb, '-', mae_gb]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['G1', 'G2']\n",
    "#     y = 'G3'\n",
    "#     mse_gb, mae_gb = pred_gradient_boosting_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Gradient Boosting', str(X), str(y), mse_gb, '-', mae_gb]\n",
    "\n",
    "\n",
    "\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G1'\n",
    "#     mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G1'\n",
    "#     mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = ['G1', 'G2']\n",
    "#     mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['G1', 'G2']\n",
    "#     y = 'G3'\n",
    "#     mse_knn, mae_knn = pred_knn_regression(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'KNN', str(X), str(y), mse_knn, '-', mae_knn]\n",
    "\n",
    "\n",
    "\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G1'\n",
    "#     mse_lgbm, mae_lgbm = pred_light_gbm(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), mse_lgbm, '-', mae_lgbm]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "#     y = 'G2'\n",
    "#     mse_lgbm, mae_lgbm = pred_light_gbm(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), mse_lgbm, '-', mae_lgbm]\n",
    "# for name, i in zip(df_names, dfs):\n",
    "#     X = ['G1', 'G2']\n",
    "#     y = 'G3'\n",
    "#     mse_lgbm, mae_lgbm = pred_light_gbm(i, X, y)\n",
    "#     coefs.loc[len(coefs)] = [name, 'Light GBM', str(X), str(y), mse_lgbm, '-', mae_lgbm]\n",
    "\n",
    "# coefs['rmse'] = np.sqrt(coefs['mse'].astype(float))\n",
    "\n",
    "# coefs['rmse'] = coefs['rmse'].apply(lambda x: round(x, 2))\n",
    "# coefs['mse'] = coefs['mse'].apply(lambda x: round(x, 2))\n",
    "# coefs['mae'] = coefs['mae'].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_gradient_boosting_regression_grid_search(df, X, y):\n",
    "\n",
    "    param_grid_gb = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    grid_search_gb = GridSearchCV(\n",
    "        estimator = GradientBoostingRegressor(),\n",
    "        param_grid = param_grid_gb,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search_gb.best_params_, grid_search_gb.best_score_ * -1\n",
    "\n",
    "\n",
    "def pred_knn_regression_grid_search(df, X, y):\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "\n",
    "    grid_search_knn = GridSearchCV(\n",
    "        estimator = KNeighborsRegressor(),\n",
    "        param_grid = param_grid_knn,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    return grid_search_knn.best_params_, grid_search_knn.best_score_ * -1\n",
    "\n",
    "\n",
    "def pred_decision_tree_grid_search(df, X, y):\n",
    "\n",
    "    param_grid_dt = {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    grid_search_dt = GridSearchCV(\n",
    "        estimator = DecisionTreeRegressor(),\n",
    "        param_grid = param_grid_dt,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search_dt.best_params_, grid_search_dt.best_score_ * -1\n",
    "\n",
    "\n",
    "def pred_light_gbm_grid_search(df, X, y):\n",
    "\n",
    "    param_grid_lgbm = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [20, 31, 40],\n",
    "        'max_depth': [-1, 10, 20],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    grid_search_lgbm = GridSearchCV(\n",
    "        estimator = lgbm.LGBMRegressor(),\n",
    "        param_grid = param_grid_lgbm,\n",
    "        cv = 5,  #\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    grid_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search_lgbm.best_params_, grid_search_lgbm.best_score_ * -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs2 = pd.DataFrame({\n",
    "    'materia': [],\n",
    "    'modelo': [],\n",
    "    'x': [],\n",
    "    'variavel_target': [],\n",
    "    'mae': []\n",
    "})\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_decision_tree_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Arvore de Decisao', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_decision_tree_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Arvore de Decisao', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_decision_tree_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Arvore de Decisao', str(X), str(y), best_score_]\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_gradient_boosting_regression_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Gradient Boosting', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_gradient_boosting_regression_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Gradient Boosting', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_gradient_boosting_regression_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Gradient Boosting', str(X), str(y), best_score_]\n",
    "\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_knn_regression_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'KNN', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_knn_regression_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'KNN', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_knn_regression_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'KNN', str(X), str(y), best_score_]\n",
    "\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_light_gbm_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Light GBM', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_light_gbm_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Light GBM', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_light_gbm_grid_search(dfs[0], X, y)\n",
    "    coefs2.loc[len(coefs2)] = [name, 'Light GBM', str(X), str(y), best_score_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_gradient_boosting_regression_random_search(df, X, y):\n",
    "\n",
    "    param_dist_gb = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    random_search_gb = RandomizedSearchCV(\n",
    "        estimator = GradientBoostingRegressor(),\n",
    "        param_distributions = param_dist_gb,\n",
    "        n_iter = 20,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error',\n",
    "        n_jobs = -1,\n",
    "        random_state = 42\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "    return random_search_gb.best_params_, random_search_gb.best_score_ * -1\n",
    "\n",
    "\n",
    "def pred_knn_regression_random_search(df, X, y):\n",
    "\n",
    "    param_dist_knn = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    random_search_knn = RandomizedSearchCV(\n",
    "        estimator = GradientBoostingRegressor(),\n",
    "        param_distributions = param_dist_knn,\n",
    "        n_iter = 20,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error',\n",
    "        n_jobs = -1,\n",
    "        random_state = 42\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    random_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    return random_search_knn.best_params_, random_search_knn.best_score_ * -1\n",
    "\n",
    "\n",
    "def pred_decision_tree_random_search(df, X, y):\n",
    "\n",
    "    param_dist_dt = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    random_search_dt = RandomizedSearchCV(\n",
    "        estimator = GradientBoostingRegressor(),\n",
    "        param_distributions = param_dist_dt,\n",
    "        n_iter = 20,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error',\n",
    "        n_jobs = -1,\n",
    "        random_state = 42\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    random_search_dt.fit(X_train, y_train)\n",
    "\n",
    "    return random_search_dt.best_params_, random_search_dt.best_score_ * -1\n",
    "\n",
    "\n",
    "def pred_light_gbm_random_search(df, X, y):\n",
    "\n",
    "    param_dist_lgbm = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    random_search_lgbm = RandomizedSearchCV(\n",
    "        estimator = GradientBoostingRegressor(),\n",
    "        param_distributions = param_dist_lgbm,\n",
    "        n_iter = 20,\n",
    "        cv = 5,\n",
    "        scoring = 'neg_mean_squared_error',\n",
    "        n_jobs = -1,\n",
    "        random_state = 42\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size = 0.2, random_state = 42)\n",
    "    random_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "    return random_search_lgbm.best_params_, random_search_lgbm.best_score_ * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs3 = pd.DataFrame({\n",
    "    'materia': [],\n",
    "    'modelo': [],\n",
    "    'x': [],\n",
    "    'variavel_target': [],\n",
    "    'mse': []\n",
    "})\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_decision_tree_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Arvore de Decisao', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_decision_tree_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Arvore de Decisao', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_decision_tree_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Arvore de Decisao', str(X), str(y), best_score_]\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_gradient_boosting_regression_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Gradient Boosting', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_gradient_boosting_regression_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Gradient Boosting', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_gradient_boosting_regression_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Gradient Boosting', str(X), str(y), best_score_]\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_knn_regression_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'KNN', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_knn_regression_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'KNN', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_knn_regression_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'KNN', str(X), str(y), best_score_]\n",
    "\n",
    "\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G1'\n",
    "    best_params_, best_score_ = pred_light_gbm_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Light GBM', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['failures', 'studytime', 'Medu', 'Fedu', 'school_GP', 'school_MS', 'higher_Nao', 'higher_Sim', 'internet_Nao', 'internet_Sim']\n",
    "    y = 'G2'\n",
    "    best_params_, best_score_ = pred_light_gbm_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Light GBM', str(X), str(y), best_score_]\n",
    "for name, i in zip(df_names, dfs):\n",
    "    X = ['G1', 'G2']\n",
    "    y = 'G3'\n",
    "    best_params_, best_score_ = pred_light_gbm_random_search(dfs[0], X, y)\n",
    "    coefs3.loc[len(coefs3)] = [name, 'Light GBM', str(X), str(y), best_score_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning de Hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vamos aplicar técnicas chamadas de Tuning de Hiperparametros.\n",
    "\n",
    "##### Isso nada mais é do que ajustes que podemos fazer para calibrar alguns parâmetros de como o algoritmo aplica suas fórmulas.\n",
    "\n",
    "##### O objetivo disso é vermos se alguns modelos podem ter sua eficiencia melhorada e oferecer melhores resultados, num escopo de diferentes valores.\n",
    "\n",
    "##### Vamos utilizar 2 técnicas para realizar esses ajustes:\n",
    "\n",
    "- Grid Search\n",
    "- Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As tabelas acima nos mostram o seguinte:\n",
    "\n",
    "##### A primeira tabela (Referente ao ajuste de Grid Search), podemos observar que em média, temos uma métrica de MAE (Erro médio absoluto) de aproximadamente 2,5, em comparação de erros acima de 3 e quase 4 quando comparados antes dos ajustes.\n",
    "\n",
    "##### Isso significa que a calibragem do Grid Search ajudou o modelo à performar melhor e fazer predições melhores e com menos erros.\n",
    "\n",
    "##### A segunda tabela (Referente ao ajuste de Random Search), podemos observar que em média, temos uma métrica de MSE (Erro quadrático médio) de aproximadamente 9 e 13, em comparação de erros de antes dos ajustes.\n",
    "\n",
    "##### Isso significa que a calibragem do Random Search não ajudou o modelo à performar melhor e fazer predições melhores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões Finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com tudo o que vimos nos dados dos estudantes, podemos tirar algumas conclusões:\n",
    "\n",
    "1) Quanto mais tempo o aluno passa estudando, maior é a nota. Essa correlação é quase o dobro em Português do que em Matemática.\n",
    "\n",
    "2) Isso explica o aumento de notas baixas durante o ano, significando que esta matéria fique bastante difícil com relação ao tempo, de maneira que nem um aluno que passa muito tempo estudando consiga um bom desempenho.\n",
    "\n",
    "3) Há um menor tempo de dedicação aos estudos em matemática, por causa da crescente complexidade na matéria ao longo do ano, isso pode fazer com que os alunos acabem se \"desmotivando\" para estudar.\n",
    "\n",
    "4) Alunos da escola Gabriel Pereira tem uma nota em português maior do que os alunos da escola Mousinho da Silveira.\n",
    "\n",
    "5) A estrutura familiar do aluno não se relaciona tanto com a quantidade de horas que o aluno estuda e suas notas.\n",
    "\n",
    "6) Alunos da zona urbana tem uma média de notas superior à alunos que moram em área rual. Assim como os que estudam mais longe de casa tem uma nota menor dos que estudam mais perto de casa.\n",
    "\n",
    "7) Alunos com suporte educacional extra tendem a concentrar suas notas entre 7.5 e 10, alunos sem suporte adquirem uma frequência maior de notas 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propostas\n",
    "\n",
    "##### Propomos, então, a implementação dos seguintes modelos de modo a mitigar os principais problemas apresentados acima:\n",
    "\n",
    "## 1 - Aumentar interesse do aluno.\n",
    "\n",
    "##### Aumentar o interesse do aluno em estudar matemática ao diminuir o foco em decorar fórmulas onde isso ocorre, ao invés, trazer problemas mais palpáveis do ambiente do aluno para a sala de aula, mostrando onde tais numeros, fórmulas e metodologias se aplicam ao cotidiano do contexto em que o aluno está inserido, fazendo-o perceber como a matemática se aplica ao seu próprio dia a dia.\n",
    "\n",
    "##### Exemplo: como alunos em um contexto rural tem notas menores, podemos ensinar matemática num contexto rural e de campo, mostrando como a matemática se aplica em diferentes áreas e ciclos de plantio, como a matemática foi usada na construção de casas na época dos grandes latifúndios, conceitos de matemática e física que se aplicam à GPS, ferramenta muito usada no controle de máquinas agrícolas.\n",
    "\n",
    "## 2 - Recompensar esforço.\n",
    "\n",
    "##### Ao diminuir um pouco a quantidade e complexidade do conteúdo, ao decorar menos fórmulas e entender mais, o aluno se sente mais recompensado, e consequentemente mais motivado à estudar mais, quando vê que seu entendimento foi convertido em uma nota maior.\n",
    "\n",
    "##### Exemplo: Compor parte da média final com várias lições de casa e trabalhos, pode estimular o aluno à se dedicar apenas um pouco mais todos os dias, aumentando o número de horas que passa estudando sem nem perceber que está estudando, e não apenas motivar o aluno à estudar somente em vésperas de provas.\n",
    "\n",
    "## 3 - Estudo da escola Gabriel Pereira.\n",
    "\n",
    "##### Realizar um estudo mais aprofundado e detalhado sobre as diferenças das didáticas e planos estudantis das duas escolas:\n",
    "\n",
    "- Como são as aulas dos professores ? E suas formações ?\n",
    "- O quão atualizado é o material didático ? Há diferença entre eles ?\n",
    "- Há diferenças nos valores da escola ?\n",
    "- Como estão estruturados os horários e intervalos ?\n",
    "- Há diferença entre aplicabilidade de provas ?\n",
    "\n",
    "##### Estes questionamentos devem ser feitos a fim de entender melhor a causa das notas da escola Gabriel Pereira serem melhores, e, partir destes pontos, traçar um plano para a analisar as possíveis implementações e mudanças a serem feitas na escola Mousinho da Silveira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fim entrega 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
